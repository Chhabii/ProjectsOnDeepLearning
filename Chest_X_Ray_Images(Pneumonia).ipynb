{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chest X-Ray Images(Pneumonia).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPy/j+6ElhHnXTwb87xy/ig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RxnAch/ProjectsOnDeepLearning/blob/main/Chest_X_Ray_Images(Pneumonia).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvgBlIuQ10S_"
      },
      "source": [
        "#Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Un7IbU_0Q7"
      },
      "source": [
        "%matplotlib inline\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import skimage\n",
        "from skimage import io, transform \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets,models,transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8mnleC613t-"
      },
      "source": [
        "#Load Dataset \n",
        "- test set\n",
        "- train set\n",
        "- validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khXP7jEROIzo"
      },
      "source": [
        "data_dir = \"/content/drive/MyDrive/datasets/kaggle_dataset/ChestXray/chest_xray/chest_xray\"\n",
        "TEST = 'test'\n",
        "TRAIN = 'train'\n",
        "VAL = 'val'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSJCqFaE2HAG"
      },
      "source": [
        "#Data Preprocessing and Augmentation\n",
        "\n",
        "Deeplearning models requires a lot of data.In fact,the more the data,the better the performance of the model.\n",
        "\n",
        "Image Augmentation is the process of generating new images for training our deep learning models. These images are generated using the existing training images and hence we don't have to collect them manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rr3KysU5uAI"
      },
      "source": [
        "**transforms.Compose** just clubs all the transforms provided to it. So, all the transforms in the transforms.Compose are applied to the input one by one.\n",
        "\n",
        "#**Train transforms**\n",
        "**transforms.RandomResizedCrop(224)**:\n",
        "\n",
        " This will extract a patch of size (224, 224) from your input image randomly. So, it might pick this path from topleft, bottomright or anywhere in between. So, you are doing data augmentation in this part. Also, changing this value won't play nice with the fully-connected layers in your model, so not advised to change this.\n",
        "\n",
        "**transforms.RandomHorizontalFlip():** \n",
        "\n",
        "Once we have our image of size (224, 224), we can choose to flip it. This is another part of data augmentation.\n",
        "transforms.ToTensor(): This just converts your input image to PyTorch tensor.\n",
        "\n",
        "\n",
        "**transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]):** This is just input data scaling and these values (mean and std) must have been precomputed for your dataset. Changing these values is also not advised.\n",
        "\n",
        "#**Validation transforms**\n",
        "**transforms.Resize(256):**\n",
        "\n",
        " First your input image is resized to be of size (256, 256)\n",
        "**transforms.CentreCrop(224):** \n",
        "\n",
        "Crops the center part of the image of shape (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjDJng4qTX9H"
      },
      "source": [
        "def data_transforms(phase):\n",
        "  if phase == TRAIN:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "  if phase == VAL:\n",
        "    transform = transforms.Compose([\n",
        "         transforms.Resize(256),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.ToTensor(),\n",
        "         transforms.\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}